# Context-Aware Safety Guardrails via Latent Space Steering

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-EE4C2C)](https://pytorch.org/)
[![Model](https://img.shields.io/badge/Model-Qwen--14B-yellow)](https://huggingface.co/Qwen)

> **Dynamic Safety Policy Switching for LLMs without Fine-tuning.** > **íŒŒì¸íŠœë‹ ì—†ì´, ì ì¬ ê³µê°„ ì œì–´(Steering)ë§Œìœ¼ë¡œ LLMì˜ ì•ˆì „ ì •ì±…ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¡°ì ˆí•˜ëŠ” ê°œì¸ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.**

<br>

## ğŸŒ Language
* [English](#-english-description)
* [í•œêµ­ì–´ (Korean)](#-project-description-in-korean)

---

## ğŸš€ English Description

### 1. Introduction
Current Large Language Models (LLMs) often suffer from **"Safety Over-refusal"** due to rigid RLHF alignment. They tend to block queries involving conflict or violence even in fictional contexts (e.g., game scenarios, creative writing), while a single generic safety standard is insufficient for high-risk domains like finance.

This project implements **Inference-time Latent Space Steering** to dynamically modulate the model's safety guardrails. By manipulating the internal activation vectors, we can switch the model between **Game Mode (Relaxed Safety)** and **Finance Mode (Strict Safety)** in real-time without expensive fine-tuning.

### 2. Methodology
We utilized **Representation Engineering (RepE)** techniques:
1.  **Diagnosis (Linear Probing):** Constructed a contrastive dataset (Game Safe vs. Finance Unsafe) to identify the "Safety Direction" vector in the latent space.
2.  **Control (Activation Steering):** Applied arithmetic operations to the hidden states during the forward pass.
    * $$H' = H + (\alpha \cdot v_{safety})$$
    * **Negative Steering ($\alpha < 0$):** Suppresses safety mechanisms (Game Mode).
    * **Positive Steering ($\alpha > 0$):** Enhances safety mechanisms (Finance Mode).

### 3. Key Results
* **Optimal Layer:** The safety concept is most distinct at **Layer 20** of Qwen-14B.
* **Performance:**
    * **Baseline ($\alpha=0$):** 92.5% Refusal Rate (Highly biased).
    * **Game Mode ($\alpha=-40$):** **70.0% Refusal Rate**.
    * Achieved a **22.5%p improvement** in responsiveness for fictional contexts.

### 4. How to Run
```bash
# 1. Clone the repository
git clone [https://github.com/YOUR_ID/LLM-Latent-Space-Steering.git](https://github.com/YOUR_ID/LLM-Latent-Space-Steering.git)
cd LLM-Latent-Space-Steering

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run Steering Demo
# --coeff: Steering coefficient (negative for game mode)
# --layer: Target layer index
python steer_main.py --model "Qwen/Qwen-14B-Chat" --coeff -40 --layer 20
```
## ğŸ‡°ğŸ‡· Project Description in Korean

### 1. í”„ë¡œì íŠ¸ ê°œìš” (Overview)
ìµœì‹  LLMì€ RLHF(ì¸ê°„ í”¼ë“œë°± ê°•í™”í•™ìŠµ)ë¥¼ í†µí•´ ì•ˆì „ì„±ì´ ê°•í™”ë˜ì—ˆì§€ë§Œ, ì´ë¡œ ì¸í•´ ê²Œì„ì´ë‚˜ ì†Œì„¤ ì°½ì‘ê³¼ ê°™ì€ í—ˆêµ¬ì  ìƒí™©ì—ì„œë„ ë¬¸ë§¥ì„ íŒŒì•…í•˜ì§€ ëª»í•˜ê³  ë‹µë³€ì„ ê±°ì ˆí•˜ëŠ” 'ê³¼ì‰ ë°©ì–´(Over-refusal)' ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.

ë³¸ í”„ë¡œì íŠ¸ëŠ” Representation Engineering (RepE) ê¸°ìˆ ì„ í™œìš©í•˜ì—¬, ëª¨ë¸ì˜ ì¬í•™ìŠµ(Fine-tuning) ì—†ì´ ì¶”ë¡  ë‹¨ê³„ì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ì•ˆì „ ê°€ë“œë ˆì¼ì˜ ë†’ë‚®ì´ë¥¼ ì¡°ì ˆí•˜ëŠ” ê¸°ìˆ ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ 'ììœ ë„ê°€ ë†’ì€ ê²Œì„ NPC'ì™€ 'ì—„ê²©í•œ ê¸ˆìœµ ì „ë¬¸ê°€'ì˜ í˜ë¥´ì†Œë‚˜ë¥¼ ììœ ë¡­ê²Œ ì˜¤ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 2. í•µì‹¬ ê¸°ìˆ  ë° ë°©ë²•ë¡  (Methodology)
   * ë°ì´í„°ì…‹ êµ¬ì¶•: 'ê³µê²©ì ì´ì§€ë§Œ í—ˆìš© ê°€ëŠ¥í•œ ê²Œì„ ìš©ì–´' vs 'ì‹¤ì œ ìœ„í—˜í•œ ë²”ì£„ ëª¨ì˜'ë¥¼ ëŒ€ì¡°í•˜ëŠ” ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ì—¬ ëª¨ë¸ ë‚´ë¶€ì˜ **ì•ˆì „ ë²¡í„°(Safety Vector)**ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.

   * ì„ í˜• íƒì¹¨ (Linear Probing): ê° ë ˆì´ì–´ì˜ Hidden Stateë¥¼ ë¶„ì„í•˜ì—¬ ì•ˆì „/ìœ„í—˜ì„ êµ¬ë¶„í•˜ëŠ” ìµœì ì˜ ê²°ì • ê²½ê³„(Decision Boundary)ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.

   * ì•¡í‹°ë² ì´ì…˜ ì œì–´ (Activation Steering): Forward Pass ë„ì¤‘ íŠ¹ì • ë ˆì´ì–´ì— ë²¡í„°ë¥¼ ì£¼ì…í•˜ì—¬ ëª¨ë¸ì˜ ì„±í–¥ì„ ì œì–´í–ˆìŠµë‹ˆë‹¤.

      * Game Mode (Negative Steering): ì•ˆì „ ë²¡í„°ë¥¼ ëº„ì…ˆí•˜ì—¬ ê·œì œë¥¼ ì™„í™”í•©ë‹ˆë‹¤.

      * Compliance Mode (Positive Steering): ì•ˆì „ ë²¡í„°ë¥¼ ë§ì…ˆí•˜ì—¬ ê·œì œë¥¼ ê°•í™”í•©ë‹ˆë‹¤.
### 3. ì‹¤í—˜ ê²°ê³¼ ë° ì¸ì‚¬ì´íŠ¸ (Results & Insights)
   Layer 20ì˜ ë°œê²¬: ëª¨ë“  ë ˆì´ì–´ê°€ ì•„ë‹Œ, ë„¤íŠ¸ì›Œí¬ ì¤‘ë°˜ë¶€ì¸ Layer 20ì—ì„œ ì•ˆì „ íŒë‹¨ì´ í˜•ì„±ë¨ì„ ê·œëª…í–ˆìŠµë‹ˆë‹¤.

   ì •ëŸ‰ì  ì„±ê³¼:

      ê¸°ë³¸ ìƒíƒœ(Baseline) ê±°ì ˆë¥ : 92.5%

      ê²Œì„ ëª¨ë“œ(Coeff -40) ì ìš© ì‹œ ê±°ì ˆë¥ : 70.0%

      ê²°ê³¼: 22.5%pì˜ ì‘ë‹µì„± ê°œì„ ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

   í•µì‹¬ ì¸ì‚¬ì´íŠ¸: "0ì€ ì¤‘ë¦½ì´ ì•„ë‹ˆë‹¤."

      ì•„ë¬´ëŸ° ê°œì…ì´ ì—†ëŠ” ìƒíƒœ(Coefficient 0)ì—ì„œë„ ëª¨ë¸ì€ ì´ë¯¸ ì•ˆì „ í¸í–¥ì´ ì‹¬í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì§„ì •í•œ ì¤‘ë¦½ì´ë‚˜ ê²Œì„ ëª¨ë“œë¥¼ êµ¬í˜„í•˜ë ¤ë©´ ë‹¨ìˆœí•œ ê°€ë“œë ˆì¼ í•´ì œê°€ ì•„ë‹Œ **ëŠ¥ë™ì ì¸ ë²¡í„° ëº„ì…ˆ(Negative Steering)**ì´ í•„ìˆ˜ì ì„ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

### 4. ì‹¤í–‰ ë°©ë²• (Usage)
ì´ ì½”ë“œëŠ” Qwen-14B ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤. (GPU ë©”ëª¨ë¦¬ 24GB ì´ìƒ ê¶Œì¥)

```bash
# 1. Clone the repository
git clone [https://github.com/YOUR_ID/LLM-Latent-Space-Steering.git](https://github.com/YOUR_ID/LLM-Latent-Space-Steering.git)
cd LLM-Latent-Space-Steering

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run Steering Demo
# --coeff: Steering coefficient (negative for game mode)
# --layer: Target layer index
python steer_main.py --model "Qwen/Qwen-14B-Chat" --coeff -40 --layer 20
```
